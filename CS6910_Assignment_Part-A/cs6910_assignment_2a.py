# -*- coding: utf-8 -*-
"""CS6910_assignment-2A.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11Ka8Uupu4m2Z9HM5fmfqOUT9dfJAt9Xo
"""

import os
import numpy as np
import torch
import glob
import torch.nn as nn
from torchvision.transforms import transforms
from torch.utils.data import DataLoader
from torch.autograd import Variable
import torchvision
import pathlib
import matplotlib.pyplot as plt
from torch.utils.data.sampler import SubsetRandomSampler
from torchvision import datasets
import torch.nn.init
import torch.optim as optim

!pip install wandb -qqq
import wandb

!wandb login --relogin
entity_name="siddharth-s"

project_name="FODL_Assignment_2A"

!wget https://storage.googleapis.com/wandb_datasets/nature_12K.zip

!unzip /content/nature_12K.zip

def image_info(path):
  for folder in os.listdir(path):
      imgs=glob.glob((path+'/'+folder+'/*'))
      print("Number of images in",folder,len(imgs))

image_info('/content/inaturalist_12K/train')

image_info('/content/inaturalist_12K/val')

import cv2 as cv
img=cv.imread('/content/inaturalist_12K/train/Amphibia/015f03767b5fd30019df9ca7720cb869.jpg')
img.shape
plt.imshow(img)

class prepare_data():

  def __init__(self,augment=True,batch_size=16):
    self.train_path='/content/inaturalist_12K/train'
    self.test_path='/content/inaturalist_12K/val'
    self.augment=augment
    self.batch_size=batch_size

  def prepare(self,):
    if self.augment==True:
       train_transforms = transforms.Compose([transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomVerticalFlip(p=0.5),
            transforms.RandomRotation((120)),
            transforms.RandomApply(torch.nn.ModuleList([transforms.ColorJitter()]), p=0.5),
            transforms.Resize((224,224)),
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

       test_transforms = transforms.Compose([transforms.RandomRotation(120),
                                      transforms.Resize((224,224)),
                                      transforms.ToTensor(),
                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])
    else:
       train_transforms = transforms.Compose([transforms.Resize((224,224)),
                                       transforms.ToTensor(),                               
                                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

       test_transforms = transforms.Compose([transforms.Resize((224,224)),
                                      transforms.ToTensor(),
                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])


    train_data = datasets.ImageFolder(self.train_path, transform=train_transforms) 
    test_data = datasets.ImageFolder(self.test_path, transform=test_transforms)

    num_workers = 0
    valid_size = 0.2
    num_train = len(train_data)
    indices = list(range(num_train))
    num_train_class=1000
    split = int(np.floor(valid_size * num_train_class))
    train_id=[]
    valid_id=[]
    for i in range(10):
      x=i+1
      train_idx, valid_idx = indices[i*1000+split:x*1000], indices[i*1000:i*1000+split]
      train_id=train_id+train_idx
      valid_id=valid_id+valid_idx

    train_sampler = SubsetRandomSampler(train_id)
    valid_sampler = SubsetRandomSampler(valid_id)

    train_loader = torch.utils.data.DataLoader(train_data, batch_size=self.batch_size,
    sampler=train_sampler, num_workers=num_workers)
    valid_loader = torch.utils.data.DataLoader(train_data, batch_size=self.batch_size, 
    sampler=valid_sampler, num_workers=num_workers)
    test_loader = torch.utils.data.DataLoader(test_data, batch_size=self.batch_size, 
    num_workers=num_workers)

    return train_loader,valid_loader,test_loader

data_prep=prepare_data()
train_loader,valid_loader,test_loader = data_prep.prepare()

len(train_loader)

test_path='/content/inaturalist_12K/val'
root=pathlib.Path(test_path)
classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])
classes

# class ConvNN(nn.Module):
#   def __init__(self,dense_dim=256,kernel_size=3,num_filters_1=16,num_filters_2=32,num_filters_3=64,num_filters_4=128,num_filters_5=256, activation=nn.functional.relu,dropout=0.1,batch_norm=True):
#         super(ConvNN,self).__init__()
#         self.batch_norm=batch_norm
#         self.activation=activation
#         self.dense_dim=dense_dim
#         n=16
#         h=128
#         s=1
#         p=1

#         self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=s, padding=p)
#         self.bn1 = nn.BatchNorm2d(num_features=16)
#         self.pool1 = nn.MaxPool2d(kernel_size=2)
#         h_conv=np.floor((h-3+2) + 1)
#         h_mpool=np.floor((h_conv-2)/2 + 1)
#         h=h_mpool
        
#         self.conv2 = nn.Conv2d(in_channels=16, out_channels=num_filters_2, kernel_size=self.kernel_size, stride=1, padding=1)
#         self.bn2 = nn.BatchNorm2d(num_features=self.num_filters[1])
#         self.pool2 = nn.MaxPool2d(kernel_size=2)
#         h_conv=np.floor(h-self.kernel_size+2) + 1
#         h_mpool=np.floor((h_conv-2)/2) + 1
#         h=h_mpool
        
#         self.conv3 = nn.Conv2d(in_channels=32, out_channels=num_filters_3, kernel_size=self.kernel_size, stride=1, padding=1)
#         self.bn3 = nn.BatchNorm2d(num_features=self.num_filters[2])
#         self.pool3 = nn.MaxPool2d(kernel_size=2)
#         h_conv=np.floor(h-self.kernel_size+2) + 1
#         h_mpool=np.floor((h_conv-2)/2) + 1
#         h=h_mpool
        
#         self.conv4 = nn.Conv2d(in_channels=64, out_channels=num_filters_4, kernel_size=self.kernel_size, stride=1, padding=1)
#         self.bn4 = nn.BatchNorm2d(num_features=self.num_filters[3])
#         self.pool4 = nn.MaxPool2d(kernel_size=2)
#         h_conv=np.floor(h-self.kernel_size+2) + 1
#         h_mpool=np.floor((h_conv-2)/2) + 1
#         h=h_mpool
        
#         self.conv5 = nn.Conv2d(in_channels=128, out_channels=num_filters_5, kernel_size=self.kernel_size, stride=1, padding=1)
#         self.bn5 = nn.BatchNorm2d(num_features=self.num_filters[4])
#         self.pool5 = nn.MaxPool2d(kernel_size=2)
#         h_conv=np.floor(h-self.kernel_size+2) + 1
#         h_mpool=np.floor((h_conv-2)/2) + 1
#         h=h_mpool
        
#         self.dropout=nn.Dropout(dropout)
#         self.fc1 = nn.Linear(in_features=256 * h * h, out_features=self.dense_dim)
#         torch.nn.init.xavier_uniform_(self.fc1.weight)
#         self.fc2 = nn.Linear(in_features=self.dense_dim, out_features=10)
#         torch.nn.init.xavier_uniform_(self.fc2.weight)

def conv_out_dim(input,filter,stride=1,padding=1):
  output_dim=(input-filter+2*padding)//stride + 1
  return output_dim

def maxpool_out_dim(input,filter=2,stride=2):
  output_dim=(input-filter)//stride + 1
  return output_dim

'''
Formula to calculate output size: [(Wâˆ’K+2P)/S]+1 for conv layer
[W-K/S +1] for maxpool layer
'''
import math 
from torch.nn.functional import batch_norm
class ConvNN(nn.Module):
  def __init__(self, num_filters, kernel_size, activation,dense_dim, input=224,   dropout=0.1, batch_norm=False):
        super(ConvNN,self).__init__()
        self.batch_norm=batch_norm
        self.activation=activation
        self.dense_dim=dense_dim

        self.conv1 = nn.Conv2d(in_channels=3, out_channels=num_filters[0], kernel_size=kernel_size[0], stride=1, padding=1)
        self.bn1 = nn.BatchNorm2d(num_features=num_filters[0])
        self.pool1 = nn.MaxPool2d(kernel_size=2)
        w_conv=conv_out_dim(224,kernel_size[0])
        w_mpool=maxpool_out_dim(w_conv)
        
        self.conv2 = nn.Conv2d(in_channels=num_filters[0], out_channels=num_filters[1], kernel_size=kernel_size[1], stride=1, padding=1)
        self.bn2 = nn.BatchNorm2d(num_features=num_filters[1])
        self.pool2 = nn.MaxPool2d(kernel_size=2)
        w_conv=conv_out_dim(w_mpool,kernel_size[1])
        w_mpool=maxpool_out_dim(w_conv)

        self.conv3 = nn.Conv2d(in_channels=num_filters[1], out_channels=num_filters[2], kernel_size=kernel_size[2], stride=1, padding=1)
        self.bn3 = nn.BatchNorm2d(num_features=num_filters[2])
        self.pool3 = nn.MaxPool2d(kernel_size=2)
        w_conv=conv_out_dim(w_mpool,kernel_size[2])
        w_mpool=maxpool_out_dim(w_conv)

        self.conv4 = nn.Conv2d(in_channels=num_filters[2], out_channels=num_filters[3], kernel_size=kernel_size[3], stride=1, padding=1)
        self.bn4 = nn.BatchNorm2d(num_features=num_filters[3])
        self.pool4 = nn.MaxPool2d(kernel_size=2)
        w_conv=conv_out_dim(w_mpool,kernel_size[3])
        w_mpool=maxpool_out_dim(w_conv)

        self.conv5 = nn.Conv2d(in_channels=num_filters[3], out_channels=num_filters[4], kernel_size=kernel_size[4], stride=1, padding=1)
        self.bn5 = nn.BatchNorm2d(num_features=num_filters[4])
        self.pool5 = nn.MaxPool2d(kernel_size=2)
        w_conv=conv_out_dim(w_mpool,kernel_size[4])
        w_mpool=maxpool_out_dim(w_conv)
        w_out=num_filters[4]*w_mpool*w_mpool
        self.w_out=w_out

        self.dropout=nn.Dropout(dropout)
        self.Flatten=nn.Flatten(start_dim=1,end_dim=-1)
        self.fc1 = nn.Linear(in_features=w_out, out_features=10)
        #torch.nn.init.xavier_uniform_(self.fc1.weight)
        # self.fc2 = nn.Linear(in_features=dense_dim, out_features=10)
        #torch.nn.init.xavier_uniform_(self.fc2.weight)
      
        
  def forward(self, x):
        x = self.conv1(x)
        if self.batch_norm==True:
          x = self.bn1(x)
        x = self.activation(x)
        x = self.pool1(x)

        
        x = self.conv2(x)
        if self.batch_norm==True:
          x = self.bn2(x)
        x = self.activation(x)
        x = self.pool2(x)
        x = self.dropout(x)

        x = self.conv3(x)
        if self.batch_norm==True:
          x = self.bn3(x)
        x = self.activation(x)
        x = self.pool3(x)
        x = self.dropout(x)

        x = self.conv4(x)
        if self.batch_norm==True:
          x = self.bn4(x)
        x = self.activation(x)
        x = self.pool4(x)
        x = self.dropout(x)

        x = self.conv5(x)
        if self.batch_norm==True:
          x = self.bn5(x)
        x = self.activation(x)
        x = self.pool5(x)
        
        x = x.view(-1,self.w_out)
        x = self.fc1(x)
        # x = self.activation(x)
        # x = self.dropout(x)

        # x = self.fc2(x)
        return x

sweep_config = {
    'method': 'bayes', 
    'metric': {
      'name': 'Validation_Accuracy',
      'goal': 'maximize'   
    },
    'parameters': {
        'num_dense_dim': {
            'values': [64,256]
        },
        'num_filters' : {
           'values' : [[32,32,32,32,32],[32,64,64,128,128],[128,128,64,64,32],[16,32,64,128,256]]
        },
      'kernel_size' : {
         'values' : [[3,5,5,7,7], [7,7,5,3,3], [3,3,3,3,3]]
        },
        'dropout': {
            'values': [0.2, 0.3, 0.4]
        },
        'learning_rate': {
            'values': [1e-3, 1e-4]
        },
        'activation': {
            'values': ['relu','elu','leaky_relu']
        },
        'batch_norm':{
            'values': [True,False]
        },
        'augment': {
            'values': [True,False]
        },
        'batch_size': {
            'values': [16, 32]
        }
    }
}

def train(kernel_size=[3,3,3,3,3], num_filters=[128,128,64,64,32], dense_dim=64, activation=nn.functional.relu,dropout=0.3,batch_norm=False,augment=True, batch_size=16 ,n_epochs=20,learning_rate= 1e-4):
  
  config_defaults = {
      'num_dense_dim': dense_dim,
      'num_filters' : [128,128,64,64,32],
      'kernel_size' : [3,3,3,3,3],
      'dropout': dropout,
      'learning_rate': learning_rate,
      'activation': "relu",
      'batch_norm': batch_norm,
      'batch_size' : batch_size,
      'optimizer': 'Adam',
      'augment': augment
  }

  # Initializing the wandb run
  wandb.init(config=config_defaults)
  config = wandb.config
  
  if config.activation=="relu":
    activation=nn.functional.relu
  elif config.activation=='elu':
    activation=nn.functional.elu
  elif config.activation=='leaky_relu':
    activation=nn.functional.leaky_relu

  
  device = 'cuda' if torch.cuda.is_available() else 'cpu'
  model = ConvNN(config.num_filters,config.kernel_size,activation,config.num_dense_dim, config.dropout,config.batch_norm).to(device)

  optimizer = optim.Adam(model.parameters(),lr=config.learning_rate)
  
  criterion = nn.CrossEntropyLoss().to(device)

  data_prep=prepare_data(config.augment,config.batch_size)
  train_loader,valid_loader,test_loader = data_prep.prepare()
  n_epochs=10
  train_on_gpu = torch.cuda.is_available()
  
  ep=0
  for epoch in range(1, n_epochs+1):
     
     #scheduler.step()

     train_loss = 0.0
     valid_loss = 0.0
     val_accuracy = 0.0

     model.train()
     for data, target in train_loader:
        if train_on_gpu:
            data, target = data.cuda(), target.cuda()     
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()
        train_loss += loss.item()*data.size(0)
       
     model.eval()
     for data, target in valid_loader:
        optimizer.zero_grad()
        if train_on_gpu:
            data, target = data.cuda(), target.cuda()
        output = model(data)
        loss = criterion(output, target)
        valid_loss += loss.item()*data.size(0)
        _, pred = torch.max(output, 1)    
        ps=nn.functional.softmax(output,dim=1)
        top_p,top_c= ps.topk(1,dim=1)
        equals= target == top_c.view(*target.shape)
        val_accuracy+= equals.type(torch.FloatTensor).mean()
    

     train_loss = train_loss/len(train_loader.dataset)
     valid_loss = valid_loss/len(valid_loader.dataset)
     val_accuracy = val_accuracy/len(valid_loader)

     name_run="run" + '_' + str(config.activation) + '_' +str(config.num_dense_dim) + '_aug:' + str(config.augment)
     wandb.run.name = name_run
     wandb_log=True

     if(wandb_log==True):
       log_dict = {"Train_loss": train_loss, "Validation_loss": valid_loss, "Validation_Accuracy": val_accuracy}     
       ep=ep+1
       print('Epoch: {} \tTraining Loss: {:.5f} \tValidation Loss: {:.5f} \tValidation Accuracy: {:.5f}'.format(ep,
        train_loss, valid_loss,val_accuracy))       
       wandb.log(log_dict)
       
     
  wandb.run.save()
  wandb.run.finish()
  return model

def do_sweep(entity_name, project_name,kernel_size=[3,3,3,3,3], num_filters=[128,128,64,64,32], dense_dim=64, activation=nn.functional.relu,dropout=0.3,batch_norm=False,augment=True, batch_size=16 ,n_epochs=20,learning_rate= 1e-4):
  sweep_id=wandb.sweep(sweep_config, entity=entity_name, project=project_name)
  wandb.agent(sweep_id, train)

sweep_id = wandb.sweep(sweep_config, entity=entity_name, project=project_name)
wandb.agent(sweep_id, train)

'''
Training best config for testing
'''

model=train()

import argparse
from sys import argv
if __name__ == "__main__":
    
    entity_name = "siddharth-s"
    project_name = "FODL_Assignment_2A"
    
    #parsing the various command line arguments
    parser = argparse.ArgumentParser()
    parser.add_argument('--sweep', type=str, required=True, help="Do you want to sweep or not: Enter 'yes' or 'no'")  
    parser.add_argument('--batch_norm', type=bool, required=('no' in argv), help="Batch Normalization: True or False")
    parser.add_argument('--num_filters', type=int, required=('no' in argv), help="Number of Filters: integer value")
    parser.add_argument('--kernel_size', type=float, required=('no' in argv), help="Filter Organization: float value")
    parser.add_argument('--dropout', type=float, required=('no' in argv), help="Dropout: float value")
    parser.add_argument('--Augment', type=bool, required=('no' in argv), help="Data Augmentation: True or False")
    parser.add_argument('--n_epochs', type=int, required=('no' in argv), help="Number of Epochs: integer value")
    parser.add_argument('--batchsize', type=int, required=('no' in argv), help="Batch Size: integer value")
    parser.add_argument('--num_dense_dim', type=int, required=('no' in argv), help="Dense Layer size: integer value")
    parser.add_argument('--learning_rate', type=float, required=('no' in argv), help="Learning Rate: float value")
    parser.add_argument('--Activation', type=str, required=('no' in argv), help=" Activation function: string value")
    
    args = parser.parse_args()
    
    
    if args.sweep == 'no':
        batch_norm = args.batch_norm
        num_filters = args.num_filters
        dropout = args.dropout
        augment = args.augment
        n_epochs = args.n_epochs
        batch_size = args.batch_size
        num_dense_dim = args.num_dense_dim
        learning_rate = args.learning_rate
        kernel_size = args.kernel_size 
        activation = args.Activation
        model = train(kernel_size, num_filters, num_dense_dim,activation,dropout,batch_norm,augment, batch_size,n_epochs,learning_rate)
        
    else:
        do_sweep(entity_name, project_name)